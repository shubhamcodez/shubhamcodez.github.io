# robots.txt for Shubham Singh - Quantitative Researcher Portfolio
# Optimized for maximum visibility across search engines and LLMs

# Allow all search engines and crawlers by default
User-agent: *
Allow: /

# Disallow only static build files
Disallow: /static/

# Sitemap location
Sitemap: https://shubhamcodez.github.io/sitemap.xml

# ============================================
# LLM and AI Crawlers - Explicitly Allow All
# ============================================

# OpenAI Crawlers - For ChatGPT and OpenAI services
User-agent: GPTBot
Allow: /
Crawl-delay: 1

User-agent: ChatGPT-User
Allow: /
Crawl-delay: 1

User-agent: OAI-SearchBot
Allow: /
Crawl-delay: 1

# Google AI Crawlers - For Bard/Gemini and Google AI services
User-agent: Google-Extended
Allow: /
Crawl-delay: 1

User-agent: Googlebot
Allow: /
Crawl-delay: 1

# Anthropic Claude Crawler
User-agent: ClaudeBot
Allow: /
Crawl-delay: 1

User-agent: Claude-Web
Allow: /
Crawl-delay: 1

# Perplexity AI Crawler
User-agent: PerplexityBot
Allow: /
Crawl-delay: 1

# Common Crawl - Used by many AI/ML projects
User-agent: CCBot
Allow: /
Crawl-delay: 1

User-agent: CCBot/2.0
Allow: /
Crawl-delay: 1

# Apple AI Crawler
User-agent: Applebot-Extended
Allow: /
Crawl-delay: 1

# Bing AI Crawler
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Facebook AI Crawler
User-agent: facebookexternalhit
Allow: /
Crawl-delay: 1

# Twitter/X Crawler
User-agent: Twitterbot
Allow: /
Crawl-delay: 1

# LinkedIn Crawler
User-agent: LinkedInBot
Allow: /
Crawl-delay: 1

# Other AI/ML Research Crawlers
User-agent: anthropic-ai
Allow: /
Crawl-delay: 1

User-agent: GoogleOther
Allow: /
Crawl-delay: 1

# Academic and Research Crawlers
User-agent: ia_archiver
Allow: /
Crawl-delay: 1

# Allow all other crawlers
User-agent: *
Allow: /
Crawl-delay: 1
