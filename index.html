<!DOCTYPE html>

<html lang="en">
<head>
    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-156699410-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-156699410-1');
    </script>
    
    <meta charset="UTF-8">
    <meta http-equiv="Content-Security-Policy" content="block-all-mixed-content">

    <title>Xiaokang Chen 陈小康</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="css/style.css">
</head>

<div class="navbar navbar-fixed-top">
    <div class="container">
        <strong class="navbar-brand">Xiaokang Chen / 陈小康</strong>
        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="#about">About</a></li>
                <li><a href="#publication">Publications</a></li>
                <li><a href="#education">Education</a></li>
                <li><a href="#experiences">Experiences</a></li>
                <li><a href="#honors">Honors</a></li>
                <li><a href="#academic_activity">Activities</a></li>
            </ul>
        </div>
    </div>
</div>

<div class="gray-container" id="about">
    <div class="container">
        <div class="row">
            <div class="col-xs-4">
                <img id="me-img" src="images/cxk.png">

                <div style="margin-top: 10%; font-size: large";><strong>Xiaokang Chen / 陈小康</strong></div>
                <div style="margin-top: 5%"> Ph.D. Student at Peking University</div>
                <div style="margin-top: 5%">  pkucxk@pku.edu.cn </div>
            </div>
            <div class="col-xs-8">
                <h2>
                    <strong>Xiaokang Chen</strong>
                    <a href="">
                        <img src = "images/icon/cv.png" title = "cv" width ="36" height = "36">
                    </a>
                    <a href="https://github.com/charlesCXK" target="_blank">
                        <img src = "images/icon/github_square.png" title = "github" width ="24">
                    </a>
                    <a href="https://www.linkedin.com/in/%E5%B0%8F%E5%BA%B7-%E9%99%88-03a149120/" target="_blank">
                        <img src = "images/icon/linkedin.png" title = "linkedin" width ="24">
                    </a>
                </h2>

                <p>
                <img src="images/icon/education.png" title="education" width="24" height="24">  
                I am currently a fourth-year Ph.D student at Peking University (PKU), supervised by Professor Gang Zeng. Before that, I received my Bachelor’s degree at Peking University in July 2019.
                <br/>
                </p>

                <br/>
                <p>
                <img src="images/icon/thought.png" title="thoughts" width="24" height="24"> My research interests are in Computer Vision, including Self-Supervised Learning, 2D/2.5D Semantic Segmentation, Semantic Scene Completion and Object Detection.
                </p>

                <br/>
                </p> -->
                <div id="news"> I will graduate in 2024 and am looking for research positions in the industry!</div>

                </p> -->
                <br>
                <div>
                    <div id="news"><img src="images/icon/news.png" title="news" width="24" height="24"> News</div>
                    <div class="row work-block">
                        <ul>
                            <li>
                                2022.09 &nbsp; Our Compressible-Composable NeRF (<a href="https://arxiv.org/abs/2205.14870" target="_blank">CC-NeRF</a>) is accepted by <a href="https://nips.cc/Conferences/2022" target="_blank">NeurIPS 2022</a>. Code is available <a href="https://github.com/ashawkey/CCNeRF" target="_blank">here</a>.
                            </li>
                            <li>
                                2022.09 &nbsp; I am selected as the representative of freshmen to participate in the <a href="https://news.pku.edu.cn/xwzh/b144cb82e43a46558bb8befbbf487797.htm" target="_blank">symposium</a> held by Peking University.
                            </li>
                            
                            <li>
                                2022.07 &nbsp; One paper on Instance Mesh Reconstruction (<a href="https://arxiv.org/abs/2203.16832" target="_blank">DIMR</a>) is accepted by <a href="https://eccv2022.ecva.net/" target="_blank">ECCV 2022</a>. Code is available <a href="https://github.com/ashawkey/dimr" target="_blank">here</a>.
                            </li>
                            <li>
                                2022.02 &nbsp; Please check our <a href="https://arxiv.org/abs/2202.03026" target="_blank">CAE</a>, a novel MIM approach for self-supervised learning.
                            </li>
                            <li> 
                                2021.12 &nbsp; Joined <a href="https://home.baidu.com/" target="_blank">Baidu</a> as a research intern.
                            </li>  
                            <li> 
                                2021.12 &nbsp; One paper is accepted by <a href="https://aaai.org/Conferences/AAAI-22/" target="_blank">AAAI 2022</a>!
                            </li>   
                            <li> 
                                2021.07 &nbsp; Our <a href="https://arxiv.org/abs/2108.06152" target="_blank">Conditional DETR</a> is accepted by <a href="http://iccv2021.thecvf.com/home" target="_blank">ICCV 2021</a>! Code is available <a href="https://git.io/ConditionalDETR" target="_blank">here</a>.
                            </li>   
                            <li> 
                                2021.07 &nbsp; I am selected as <b>"Top 10 Outstanding Researcher" (学术十杰)</b>, EECS of Peking University.
                            </li>   
                            <li> 
                                2021.07 &nbsp; One paper is accepted by <a href="https://2021.acmmm.org/" target="_blank">ACM MM 2021</a>!
                            </li>   
                            <li> 
                                2021.06 &nbsp; I have released the code and data for our CVPR 2021 paper <b>CPS</b>. Please check <a href="https://github.com/charlesCXK/TorchSemiSeg" target="_blank">here</a>.
                            </li>   
                            <li> 
                                2021.03 &nbsp; One paper is accepted by <a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a>!
                            </li>   
                            <li> 
                                2020.07 &nbsp; One paper is accepted by <a href="https://eccv2020.eu/" target="_blank">ECCV 2020</a>!
                            </li>    
                            <li> 
                                2020.06 &nbsp; Joined <a href="https://www.msra.cn/" target="_blank">MSRA</a> as a research intern.
                            </li>    
                            <li> 
                                2020.05 &nbsp; One paper is accepted by <a href="https://2020.ieeeicip.org/" target="_blank">ICIP 2020</a>!
                            </li>    
                            <li> 
                                2020.03 &nbsp; One paper is accepted by <a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR 2020</a>!
                            </li>            
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<div id="rows" style="margin-left: 8%">


<div id="publication">
    <div class="container">
        <h2 class="section_title">Publications 
            <a href="https://scholar.google.com.hk/citations?view_op=list_works&hl=zh-CN&user=qALe908AAAAJ" target="_blank">
                    (<img src = "images/icon/scholar.jpg" title = "scholar" width ="28"> Google Scholar)
            </a>
        </h2>

    <!-- Paper CAE -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_CAE/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>, Mingyu Ding, Xiaodi Wang, Ying Xin, Shentong Mo, Yunhao Wang, Shumin Han, Ping Luo, Gang Zeng, Jingdong Wang
            <br>
            <strong>Context Autoencoder for Self-Supervised Representation Learning</strong>
            <br>
            <em>Arxiv Preprint, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2202.03026" target="_blank">Paper</a>] [<a href="https://github.com/lxtGH/CAE" target="_blank">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/531243540" target="_blank">中文解读</a>]
            <br>
        </div>
    </div>

    <!-- Paper D3ETR -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_D3ETR/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen*</u></font>, Jiahui Chen*, Yan Liu and Gang Zeng <br> (<font color=#e67e22>*: Equal Contribution, Xiaokang is the project leader</font>)
            <br>
            <strong>D3ETR: Decoder Distillation for Detection Transformer</strong>
            <br>
            <em><i>Arxiv Preprint</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2211.09768" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

    <!-- Paper Group DETR -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_GroupDETR/arch.png">
        </div>

        <div class="col-xs-8">
            Qiang Chen*, <font color=#e67e22><u>Xiaokang Chen</u></font>*, Jian Wang, Haocheng Feng, Junyu Han, Errui Ding, Gang Zeng and Jingdong Wang (<font color=#e67e22>*: Equal Contribution</font>)
            <br>
            <strong>Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment</strong>
            <br>
            <em><i>Arxiv Preprint</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2207.13085" target="_blank">Paper</a>] [<a href="https://zhuanlan.zhihu.com/p/549573717" target="_blank">中文解读</a>]
            <br>
        </div>
    </div>

    <!-- Paper Cond-DETR v2 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_CondDETRv2/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>, Fangyun Wei, Gang Zeng and Jingdong Wang
            <br>
            <strong>Conditional DETR V2: Efficient Detection Transformer with Box Queries</strong>
            <br>
            <em><i>Arxiv Preprint</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2207.08914" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

    <!-- Paper AAAI 2022 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/AAAI2022_SSC/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>*, Jiaxiang Tang*, Jingbo Wang* and Gang Zeng <br>(<font color=#e67e22>*: Equal Contribution, Xiaokang is the project leader</font>)
            <br>
            <strong>Not All Voxels Are Equal: Semantic Scene Completion from the Point-Voxel Perspective</strong>
            <br>
            <em><i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2112.12925" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

    <!-- Paper ICCV 2021 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ICCV2021_CondDETR/arch.png">
        </div>

        <div class="col-xs-8">
            Depu Meng*, <font color=#e67e22><u>Xiaokang Chen</u></font>*, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun and Jingdong Wang (<font color=#e67e22>*: Equal Contribution</font>)
            <br>
            <strong>Conditional DETR for Fast Training Convergence</strong>
            <br>
            <em><i>International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2021</em>
            <br>
            [<a href="https://arxiv.org/abs/2108.06152" target="_blank">Paper</a>] [<a href="https://git.io/ConditionalDETR" target="_blank">Code</a>] [<a href="https://zhuanlan.zhihu.com/p/401916664" target="_blank">中文解读</a>]
            <br>
        </div>
    </div>

    <!-- Paper CVPR 2021 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/CVPR2021_CPS/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>, Yuhui Yuan, Gang Zeng and Jingdong Wang
            <br>
            <strong>Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision</strong>
            <br>
            <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2021</em>
            <br>
            [<a href="https://arxiv.org/pdf/2106.01226.pdf" target="_blank">Paper</a>] [<a href="https://github.com/charlesCXK/TorchSemiSeg" target="_blank">Code</a>] [<a href="papers/CVPR2021_CPS/00446-poster.pdf" target="_blank">Poster</a>] [<a href="papers/CVPR2021_CPS/CVPR2021_CPS_slides.pptx">Slides</a>]  [<a href="https://www.youtube.com/watch?v=5HKitm0O27w" target="_blank">Video (YouTube)</a>] [<a href="https://zhuanlan.zhihu.com/p/378120529" target="_blank">中文解读</a>]
            <br>
        </div>
    </div>

    <!-- Paper ECCV 2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2020_RGBD_Seg/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>, Kwan-Yee Lin, Jingbo Wang, Wayne Wu, Chen Qian, Hongsheng Li, and Gang Zeng
            <br>
            <strong>Bi-directional Cross-Modality Feature Propagation with Separation-and-Aggregation Gate for RGB-D Semantic Segmentation</strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/abs/2007.09183" target="_blank">Paper</a>] [<a href="https://github.com/charlesCXK/RGBD_Semantic_Segmentation_PyTorch" target="_blank">Code</a>] 
            <br>
        </div>
    </div>

    <!-- Paper CVPR 2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/CVPR2020_3D_SketchAware_SSC/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>, Kwan-Yee Lin, Chen Qian, Gang Zeng and Hongsheng Li
            <br>
            <strong>3D Sketch-aware Semantic Scene Completion via Semi-supervised Structure Prior</strong>
            <br>
            <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/abs/2003.14052" target="_blank">Paper</a>] [<a href="https://github.com/charlesCXK/TorchSSC" target="_blank">Code</a>] [<a href="papers/CVPR2020_3D_SketchAware_SSC/02245-supp.pdf" target="_blank">Supplementary Material</a>] [<a href="papers/CVPR2020_3D_SketchAware_SSC/02245-demo.mp4" target="_blank">Demo Video</a>]
            <br>
        </div>
    </div>

    <!-- Paper ICIP 2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ICIP2020_ssc/arch.png">
        </div>

        <div class="col-xs-8">
            <font color=#e67e22><u>Xiaokang Chen</u></font>, Yajie Xing and Gang Zeng
            <br>
            <strong>Real-time Semantic Scene Completion Via Feature Aggregation and Conditioned Prediction</strong>
            <br>
            <em><i>International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/abs/2303.10967" target="_blank">Paper</a>]
        </div>
    </div>

    <!-- Paper CC-Nerf, NeurIPS 2022 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_CCNerf/arch.png">
        </div>

        <div class="col-xs-8">
            Jiaxiang Tang, <font color=#e67e22><u>Xiaokang Chen</u></font>, Jingbo Wang and Gang Zeng
            <br>
            <strong>Compressible-composable NeRF via Rank-residual Decomposition</strong>
            <br>
            <em><i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2205.14870" target="_blank">Paper</a>] [<a href="https://github.com/ashawkey/CCNeRF" target="_blank">Code</a>]
            <br>
        </div>
    </div>

    <!-- Paper DIMR, ECCV 2022 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_DIMR/arch.png">
        </div>

        <div class="col-xs-8">
            Jiaxiang Tang, <font color=#e67e22><u>Xiaokang Chen</u></font>, Jingbo Wang and Gang Zeng
            <br>
            <strong>Point Scene Understanding via Disentangled Instance Mesh Reconstruction</strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2203.16832" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

    <!-- Paper ACM MM 2021 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/MM2021_JIIF/arch.png">
        </div>

        <div class="col-xs-8">
            Jiaxiang Tang, <font color=#e67e22><u>Xiaokang Chen</u></font> and Gang Zeng
            <br>
            <strong>Joint Implicit Image Function for Guided Depth Super-Resolution</strong>
            <br>
            <em><i>ACM Multimedia (<strong>ACM MM</strong>)</i>, 2021</em>
            <br>
            [<a href="https://arxiv.org/abs/2107.08717" target="_blank">Paper</a>] [<a href="https://github.com/ashawkey/jiif" target="_blank">Code</a>]
            <br>
        </div>
    </div>

    <!-- Paper ICME 2022 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ICME2022_MaskGroup/arch.png">
        </div>

        <div class="col-xs-8">
            Min Zhong, Xinghao Chen, <font color=#e67e22><u>Xiaokang Chen</u></font>, Gang Zeng, Yunhe Wang
            <br>
            <strong>MaskGroup: Hierarchical Point Grouping and Masking for 3D Instance Segmentation</strong>
            <br>
            <em><i>IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>)</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2203.14662" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

    <!-- Paper ICIP 2019 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ICIP2019_2.5D_Conv/arch.png">
        </div>

        <div class="col-xs-8">
            Yajie Xing, Jingbo Wang, <font color=#e67e22><u>Xiaokang Chen</u></font> and Gang Zeng
            <br>
            <strong>2.5D Convolution for RGB-D Semantic Segmentation</strong>
            <br>
            <em><i>International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2019</em>
        </div>
    </div>

    <!-- Paper ICIP 2019 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ICIP2019_Idempotent_Mapping/arch.png">
        </div>

        <div class="col-xs-8">
            Yajie Xing, Jingbo Wang, <font color=#e67e22><u>Xiaokang Chen</u></font> and Gang Zeng
            <br>
            <strong>Coupling Two-Stream RGB-D Semantic Segmentation Network by Idempotent Mappings</strong>
            <br>
            <em><i>International Conference on Image Processing (<strong>ICIP</strong>)</i>, 2019</em>
        </div>
    </div>

    <!-- Paper GroupDETRv2 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_GroupDETRv2/arch.png">
        </div>

        <div class="col-xs-8">
            Qiang Chen, Jian Wang, Chuchu Han, Shan Zhang, Zexian Li, <font color=#e67e22><u>Xiaokang Chen</u></font>, Jiahui Chen, Xiaodi Wang, Shuming Han, Gang Zhang, Haocheng Feng, Kun Yao, Junyu Han, Errui Ding, Jingdong Wang
            <br>
            <strong>Group DETR v2: Strong Object Detector with Encoder-Decoder Pretraining</strong>
            <br>
            <em><i>Arxiv Preprint</i>, 2022</em> 
            <font color=#e67e22>64.5 mAP on COCO test set!</font>             
            <br>
            [<a href="https://arxiv.org/abs/2211.03594" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

    <!-- Paper CAEv2 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/2022_CAEv2/arch.png">
        </div>

        <div class="col-xs-8">
            Xinyu Zhang, Jiahui Chen, Junkun Yuan, Qiang Chen, Jian Wang, Xiaodi Wang, Shumin Han, <font color=#e67e22><u>Xiaokang Chen</u></font>, Jimin Pi, Kun Yao, Junyu Han, Errui Ding, Jingdong Wang
            <br>
            <strong>CAE v2: Context Autoencoder with CLIP Target</strong>
            <br>
            <em><i>Arxiv Preprint</i>, 2022</em>
            <br>
            [<a href="https://arxiv.org/abs/2211.09799" target="_blank">Paper</a>]
            <br>
        </div>
    </div>

</div>

<div id="education">
    <div class="container">
        <h2 class="section_title">Education</h2>
        <div class="row work-block">
            <ul>
                <li>[2022.09-2024.07] &nbsp; Phd. student at Key Laboratory of Perception (MoE), School of AI, Peking University.
                <li>[2019.09-2022.07] &nbsp; Master student at Key Laboratory of Perception (MoE), School of AI, Peking University.
                <li>[2015.09-2019.07] &nbsp; Bachelor of Science at <a href="https://eecs.pku.edu.cn/"" target="_blank">School of EECS</a>, Peking University.
            </ul>
        </div>
    </div>
</div>

<div id="experiences">
    <div class="container">
        <h2 class="section_title">Experiences</h2>
        <div class="row work-block">
            <ul>
                <li>[2022.12-now] &nbsp; Research Intern at <a href="https://www.shlab.org.cn/" target="_blank">Shanghai Artificial Intelligence Laboratory</a>, directed by Dr. <a href="https://whai362.github.io/" target="_blank">Wenhai Wang</a>.
                <li>[2021.12-2022.12] &nbsp; Research Intern at <a href="https://home.baidu.com/" target="_blank">Baidu (Artificial Intelligence Group)</a>, directed by Dr. <a href="https://jingdongwang2017.github.io/" target="_blank">Jingdong Wang</a>.
                <li>[2021.09-2021.12] &nbsp; Research Intern at <a href="https://www.msra.cn/" target="_blank">MSRA (Microsoft Research Asia)</a>, directed by Dr. <a href="https://jingdongwang2017.github.io/" target="_blank">Jingdong Wang</a> and <a href="https://scholar.google.com/citations?user=-ncz2s8AAAAJ&hl=en" target="_blank">Fangyun Wei</a>.
                <li>[2020.06-2021.09] &nbsp; Research Intern at <a href="https://www.msra.cn/" target="_blank">MSRA (Microsoft Research Asia)</a>, directed by Dr. <a href="https://jingdongwang2017.github.io/" target="_blank">Jingdong Wang</a>.
                <li>[2019.04-2020.05] &nbsp; Research Intern at <a href="https://www.sensetime.com/en/" target="_blank">SenseTime Research</a>, directed by Dr. <a href="https://kwanyeelin.github.io/" target="_blank">Kwan-Yee Lin</a> and Dr. <a href="https://wywu.github.io/" target="_blank">Wayne (Wenyan) Wu</a>.
                <li>[2021.03-2021.06] &nbsp; TA of <i>"Design and Analysis of Computer Algorithms, 2021"</i> at Peking University.
                <li>[2019.03-2019.06] &nbsp; TA of <i>"Design and Analysis of Computer Algorithms, 2019"</i> at Peking University.
            </ul>
        </div>
    </div>
</div>


<div id="honors">
    <div class="container">
        <h2 class="section_title">Selected Honors</h2>
        <div class="row work-block">
            <ul>
                <li>National Scholarship, (Ministry of Education, People's Republic of China), 2021, 2022 </li>
                <li>Merit Student of Peking University, PKU, 2020, 2021, 2022 </li>
                <li>Award for Academic Innovation, PKU, 2021 </li>
                <li>Top 10 Outstanding Researcher (学术十杰), EECS of Peking University, 2021 </li>
                <li>Huawei Scholarship, PKU, 2021 </li>
                <li>Schlumberger Scholarship, PKU, 2020 </li>
                <li>Award for Excellent Research, PKU, 2019 </li>
                <li>Award for Academic Excellents, PKU, 2018 </li>
            </ul>
        </div>
    </div>
</div>

<div id="academic_activity">
    <div class="container">
        <h2 class="section_title">Academic Activities</h2>
        <div class="row work-block">
            <ul>
                <li>Conference reviewer of: AAAI (2022,2023), NeurIPS (2022), ICML (2022), CVPR (2022,2023), ECCV (2022), ICCV (2021,2023). </li>
                <li>Journal reviewer of: IJCV (2021,2022), TPAMI (2021), TIP (2022), TCSVT (2022), Neurocomputing (2022), CVIU (2022). </li>
            </ul>
        </div>
    </div>
</div>

<div class="container footer">
    <div class="row">
        <div class="text-center">
        Xiaokang Chen @2022 &nbsp;&nbsp;&nbsp;&nbsp; Total Visitors:
        <a href='https://www.counter12.com'><img src='https://www.counter12.com/img-82b92YYyyBDcAY24-26.gif' border='0' alt='conter12'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=82b92YYyyBDcAY24'></script>
        </div>
    </div>
</div>



</body>
</html>
